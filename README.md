# NLP Notebook Collection

This repository contains a collection of Jupyter notebooks focused on Natural Language Processing (NLP) tasks and techniques. Below is a brief overview of each notebook:

## Notebooks Overview

### 00_cpu_gpu.ipynb

**Basics**

- Provides an in-depth explanation of the differences between using CPU and GPU for computations in machine learning tasks.
- Guides users on how to check if CUDA (Compute Unified Device Architecture) is available on their system.
- Discusses the advantages and limitations of each hardware type and when to choose one over the other.

### 01_vector_database.ipynb

**Introduction to Vector Databases**

- Illustrates common use cases where vector databases are beneficial, such as semantic search, recommendation systems, and similarity matching.
- Discusses the underlying principles of vector databases and their role in modern NLP applications.

### 02_embeddings_genration_gensim.ipynb

**Creating Vectors/Embeddings with Different Frameworks**

- Demonstrates how to generate word embeddings using Gensim, covering techniques like Word2Vec, Doc2Vec, and FastText.
- Provides hands-on examples and practical tips for working with embeddings in NLP tasks.

### 02_sentence_transformers.ipynb

**Exploring SentenceTransformers**

- Provides an introduction to SentenceTransformers, a Python library for generating sentence embeddings using pre-trained transformer models.
- Demonstrates how to use SentenceTransformers to encode sentences into high-dimensional vectors for various NLP tasks.
- Covers advanced topics such as fine-tuning pre-trained models and evaluating model performance.

### 03_transformers.ipynb

**Working with Transformers**

- Explores the world of transformers, a groundbreaking architecture in natural language processing (NLP).
- Discusses the architecture of transformers, including self-attention mechanisms and transformer blocks.
- Demonstrates practical applications of transformers in performing various NLP tasks such as sentiment analysis, text classification, machine translation, and more.
- Introduces pipelines, tokenizers, and other key components of the transformers library.

### 04_text_classification.ipynb

**Creating Text Classification Model from Scratch**

- Focuses on building a text classification (Sentiment Analysis) model from scratch using PyTorch and other necessary ML libraries.
- Provides step-by-step guidance on data preprocessing, model architecture design, training, and evaluation.
- Includes practical tips and best practices for improving model performance and handling real-world text data challenges.

## Contribution

Contributions are welcome! If you have additional notebooks or improvements to existing ones, feel free to submit a pull request.
